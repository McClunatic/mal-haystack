"""MAL Haystack Extractive QA pipeline-in-a-node."""

from typing import List, Optional, Type

from haystack import Document
from haystack.document_stores import InMemoryDocumentStore
from haystack.nodes import BaseComponent
from haystack.nodes.retriever.base import BaseRetriever
from haystack.nodes.reader.base import BaseReader
from haystack.pipelines import ExtractiveQAPipeline


class QAExtractor(BaseComponent):
    """Component for extracting answers from single-document stores.

    Parameters:
        retriever_cls: Retriever *class* to use.
        reader: Reader instance to use.
        id_hash_keys: Generate the document id from a custom list of strings
            that refer to the document's attributes. If you want to ensure you
            don't have duplicate documents in your DocumentStore but texts are
            not unique, you can modify the metadata and pass e.g. `"meta"` to
            this field (e.g. [`"content"`, `"meta"`]). In this case the id will
            be generated by using the content and the defined metadata.
    """

    outgoing_edges = 1

    def __init__(
        self,
        retriever_cls: Type[BaseRetriever],
        reader: BaseReader,
        id_hash_keys: Optional[List[str]] = None,
    ):
        """Constructor."""

        self.retriever_cls = retriever_cls
        self.reader = reader
        self.id_hash_keys = id_hash_keys

    def extract(
        self,
        query: str,
        document: Document,
        id_hash_keys: Optional[List[str]] = None,
    ):
        """
        Arguments:
            query: The search query string.
            document: The document to extract query answers from.
            id_hash_keys: Generate the document id from a custom list of
                strings that refer to the document's attributes. If you want to
                ensure you don't have duplicate documents in your DocumentStore
                but texts are not unique, you can modify the metadata and pass
                e.g. `"meta"` to this field (e.g. [`"content"`, `"meta"`]). In
                this case the id will be generated by using the content and the
                defined metadata.
        """

        if id_hash_keys is None:
            id_hash_keys = self.id_hash_keys

        # Split document into paragraphs
        documents = []
        for num, paragraph in enumerate(document.content.split('\n\n')):
            if not paragraph.strip():
                continue
            meta = document.meta.copy()
            meta['num'] = num
            documents.append(
                Document(
                    content=paragraph,
                    meta=meta,
                    id_hash_keys=id_hash_keys))

        print(f'Document store with {len(documents)} documents')

        # Create in-memory document store
        document_store = InMemoryDocumentStore()
        document_store.write_documents(documents)

        # Create retriever against document store
        retriever = self.retriever_cls(
            document_store=document_store,
        )

        # Construct an extractive QA pipeline and run the query
        pipe = ExtractiveQAPipeline(self.reader, retriever)
        return pipe.run(query=query)

    def run(
        self,
        query: str,
        documents: List[Document],
        id_hash_keys: Optional[List[str]] = None,
    ):
        """Extract `query` answers `from `documents`.

        Arguments:
            query: The search query string.
            document: The document to extract query answers from.
            id_hash_keys: Generate the document id from a custom list of
                strings that refer to the document's attributes. If you want to
                ensure you don't have duplicate documents in your DocumentStore
                but texts are not unique, you can modify the metadata and pass
                e.g. `"meta"` to this field (e.g. [`"content"`, `"meta"`]). In
                this case the id will be generated by using the content and the
                defined metadata.
        """

        answers = []
        for document in documents:
            answers.append(self.extract(
                query=query,
                document=document,
                id_hash_keys=id_hash_keys,
            ))

        return {'answers': answers}, 'output_1'

    run_batch = run
